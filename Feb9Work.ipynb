{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which review do you want me to clean (enter a row number beween 2 and 29273)?29272\n",
      "Raw review text:\n",
      "================\n",
      "Good concept, but on my nexus 7 I have the kids profiles as well as my own they are setup as restricted profiles under mine. Not running controls on my profile, but it locks out MY internet restricts it to the xooloo homepage, because the kids profiles are restricted. I even went and tried running it for mine as adult, no good still locked out. Needs an overall screen time lock not just individual app time lock. You can't know what the kids will play every second. only using it as a lockout on settings now\n",
      "Tokenized text:\n",
      "===============\n",
      "['Good', 'concept', ',', 'but', 'on', 'my', 'nexus', '7', 'I', 'have', 'the', 'kids', 'profiles', 'as', 'well', 'as', 'my', 'own', 'they', 'are', 'setup', 'as', 'restricted', 'profiles', 'under', 'mine', '.', 'Not', 'running', 'controls', 'on', 'my', 'profile', ',', 'but', 'it', 'locks', 'out', 'MY', 'internet', 'restricts', 'it', 'to', 'the', 'xooloo', 'homepage', ',', 'because', 'the', 'kids', 'profiles', 'are', 'restricted', '.', 'I', 'even', 'went', 'and', 'tried', 'running', 'it', 'for', 'mine', 'as', 'adult', ',', 'no', 'good', 'still', 'locked', 'out', '.', 'Needs', 'an', 'overall', 'screen', 'time', 'lock', 'not', 'just', 'individual', 'app', 'time', 'lock', '.', 'You', 'ca', \"n't\", 'know', 'what', 'the', 'kids', 'will', 'play', 'every', 'second', '.', 'only', 'using', 'it', 'as', 'a', 'lockout', 'on', 'settings', 'now']\n",
      "Tokenized text without punctuation:\n",
      "===================================\n",
      "[['Good', 'concept', 'but', 'on', 'my', 'nexus', '7', 'I', 'have', 'the', 'kids', 'profiles', 'as', 'well', 'as', 'my', 'own', 'they', 'are', 'setup', 'as', 'restricted', 'profiles', 'under', 'mine', 'Not', 'running', 'controls', 'on', 'my', 'profile', 'but', 'it', 'locks', 'out', 'MY', 'internet', 'restricts', 'it', 'to', 'the', 'xooloo', 'homepage', 'because', 'the', 'kids', 'profiles', 'are', 'restricted', 'I', 'even', 'went', 'and', 'tried', 'running', 'it', 'for', 'mine', 'as', 'adult', 'no', 'good', 'still', 'locked', 'out', 'Needs', 'an', 'overall', 'screen', 'time', 'lock', 'not', 'just', 'individual', 'app', 'time', 'lock', 'You', 'ca', 'nt', 'know', 'what', 'the', 'kids', 'will', 'play', 'every', 'second', 'only', 'using', 'it', 'as', 'a', 'lockout', 'on', 'settings', 'now']]\n",
      "Text without stopwords:\n",
      "========================\n",
      "[['Good', 'concept', 'nexus', '7', 'I', 'kids', 'profiles', 'well', 'setup', 'restricted', 'profiles', 'mine', 'Not', 'running', 'controls', 'profile', 'locks', 'MY', 'internet', 'restricts', 'xooloo', 'homepage', 'kids', 'profiles', 'restricted', 'I', 'even', 'went', 'tried', 'running', 'mine', 'adult', 'good', 'still', 'locked', 'Needs', 'overall', 'screen', 'time', 'lock', 'individual', 'app', 'time', 'lock', 'You', 'ca', 'nt', 'know', 'kids', 'play', 'every', 'second', 'using', 'lockout', 'settings']]\n",
      "Text after stemming:\n",
      "====================\n",
      "[['good', 'concept', 'nexus', '7', 'i', 'kid', 'profil', 'well', 'setup', 'restrict', 'profil', 'mine', 'not', 'run', 'control', 'profil', 'lock', 'my', 'internet', 'restrict', 'xooloo', 'homepag', 'kid', 'profil', 'restrict', 'i', 'even', 'went', 'tri', 'run', 'mine', 'adult', 'good', 'still', 'lock', 'need', 'overal', 'screen', 'time', 'lock', 'individu', 'app', 'time', 'lock', 'you', 'ca', 'nt', 'know', 'kid', 'play', 'everi', 'second', 'use', 'lockout', 'set']]\n"
     ]
    }
   ],
   "source": [
    "#Deliverable: A clean dataset i.e. given the input dataset, please clean this by removing\n",
    "#the stem and stop words from the textual data of the reviews and creating an output “clean” \n",
    "#dataset which does not contain these words. Your code should be able to test this by asking \n",
    "#for any review no and then outputting the clean text of the review on the page. \n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "#loading workbook\n",
    "wb=load_workbook('TeenSafetyApps_Reviews.xlsx')\n",
    "wb.get_sheet_names()\n",
    "sheet = wb.get_sheet_by_name('all_reviews')\n",
    "\n",
    "#print sheet details\n",
    "#sheet.title\n",
    "#type(sheet)\n",
    "#for x in range (2,29274):\n",
    "#    print(x,sheet.cell(row=x,column=5).value)\n",
    "\n",
    "#xstr(s) returns string when s is not none\n",
    "def xstr(s):\n",
    "    return '' if s is None else str(s)\n",
    "\n",
    "#select review text\n",
    "x = input('Which review do you want me to clean (enter a row number beween 2 and 29273)?')\n",
    "# get content into text\n",
    "text = \"\"\n",
    "text = xstr(sheet.cell(row=int(x),column=5).value)    \n",
    "print(\"Raw review text:\")\n",
    "print(\"================\")\n",
    "print(text)\n",
    "\n",
    "#tokenizing text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_text = word_tokenize(text) \n",
    "print(\"Tokenized text:\")\n",
    "print(\"===============\")\n",
    "print(tokenized_text)\n",
    "\n",
    "#removing punctuation\n",
    "import re\n",
    "import string\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation)) \n",
    "\n",
    "tokenized_text_no_punctuation = []\n",
    "\n",
    "#for review in tokenized_text:\n",
    "new_review = []\n",
    "for token in tokenized_text: \n",
    "    new_token = regex.sub(u'', token)\n",
    "    if not new_token == u'':\n",
    "        new_review.append(new_token)\n",
    "    \n",
    "tokenized_text_no_punctuation.append(new_review)\n",
    "print(\"Tokenized text without punctuation:\")\n",
    "print(\"===================================\")    \n",
    "print(tokenized_text_no_punctuation)\n",
    "\n",
    "#cleaning stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenized_text_no_stopwords = []\n",
    "for doc in tokenized_text_no_punctuation:\n",
    "    new_term_vector = []\n",
    "    for word in doc:\n",
    "        if not word in stopwords.words('english'):\n",
    "            new_term_vector.append(word)\n",
    "    tokenized_text_no_stopwords.append(new_term_vector)\n",
    "print(\"Text without stopwords:\")\n",
    "print(\"========================\")            \n",
    "print(tokenized_text_no_stopwords)\n",
    "\n",
    "#stemming/lemmatizing\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "#wordnet = WordNetLemmatizer()\n",
    "\n",
    "preprocessed_text = []\n",
    "\n",
    "for doc in tokenized_text_no_stopwords:\n",
    "    final_doc = []\n",
    "    for word in doc:\n",
    "        #final_doc.append(porter.stem(word))\n",
    "        final_doc.append(snowball.stem(word))\n",
    "        #final_doc.append(wordnet.lemmatize(word)) \n",
    "    preprocessed_text.append(final_doc)\n",
    "print(\"Text after stemming:\")\n",
    "print(\"====================\")  \n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
